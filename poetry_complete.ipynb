{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing as p\n",
    "import nltk as n\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S N AE1 P IH0 EH2 S T']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.phones_for_word(\"snappiest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621613"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress_string = \"0101010101\"\n",
    "# markov model\n",
    "\n",
    "# need a function to generate possible next words\n",
    "def get_next_word(current_word, model):\n",
    "    \"\"\"\n",
    "        :type current_word: string\n",
    "        :type mode: markov_model\n",
    "        :rtype: List[string]\n",
    "    \"\"\"\n",
    "    words = model.get_next_word(current_word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# https://stackoverflow.com/questions/21971449/how-do-i-increase-the-cell-width-of-the-jupyter-ipython-notebook-in-my-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '01', '010', '0101']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_one_zero_str(length: int, start_stress: int) -> str:\n",
    "    one_zero_str = \"\"\n",
    "    for index in range(start_stress, length + start_stress):\n",
    "        one_zero_str += str(index % 2)\n",
    "        \n",
    "    return one_zero_str\n",
    "\n",
    "def get_possible_stresses(current_stresses: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    can assume that current_stresses is 0[1,2] repeated\n",
    "    eg: current_stresses = \"010\"\n",
    "    \"\"\"\n",
    "    iamb_pent_syllables = 10\n",
    "    \n",
    "    syllables = len(current_stresses)\n",
    "    remaining_stresses = iamb_pent_syllables - syllables\n",
    "    start_stress = remaining_stresses % 2  # if even, start with 0\n",
    "    possible_stress_lengths = list(range(1, remaining_stresses + 1))\n",
    "    return list(map(lambda length: make_one_zero_str(length, start_stress), possible_stress_lengths))\n",
    "    \n",
    "get_possible_stresses(\"010101\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_matches_stress(word: str, stress_pattern_match: str) -> bool:\n",
    "    '''\n",
    "    eg: stress_pattern_match = \"010\"\n",
    "    '''\n",
    "    pronunciations = p.phones_for_word(word) # word can have more than 1 pronunciation. eg: lead of a pencil, someone lead someone\n",
    "    for pronunciation in pronunciations:\n",
    "        original_stress_pattern = p.stresses(pronunciation)\n",
    "        \n",
    "        # we consider both 1 and 2 as a stressed syllable\n",
    "        # our generated pattern match is only ever 1s and 0s\n",
    "        stress_pattern = original_stress_pattern.replace(\"2\", \"1\") \n",
    "        \n",
    "        # in case 1 pronunciation matches but the other one doesn't\n",
    "        if stress_pattern == stress_pattern_match:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "assert word_matches_stress(\"adam\", \"10\")\n",
    "assert word_matches_stress(\"janice\", \"10\")\n",
    "assert word_matches_stress(\"compare\", \"01\")\n",
    "assert word_matches_stress(\"snappiest\", \"101\") # snappiest's stresses are \"102\", so this should still match since we consider 2 as a stressed syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_possible_words(possible_stresses: List[str], words: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "        :type possible_stresses List[stress_strings]\n",
    "        :type words List[strings]\n",
    "        :filtered_words List[strings]\n",
    "    \"\"\"\n",
    "    filtered_words = []\n",
    "    for stress_pattern in possible_stresses:\n",
    "        for word in words:\n",
    "            if word_matches_stress(word, stress_pattern):\n",
    "                filtered_words.append(word)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handsome',\n",
       " 'clever',\n",
       " 'and',\n",
       " 'rich',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'unite',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'of']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = gutenberg.words()\n",
    "filtered = list(filter(lambda word: word.isalpha(), words))\n",
    "filtered_lower = [ word.lower() for word in filtered ]\n",
    "filtered_lower[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_words(current_line:List[str], current_stress_str: str, ngram_dict) -> List[str]:\n",
    "    possible_stresses = get_possible_stresses(current_stress_str)\n",
    "    candidate_words = ngram_dict.get(current_line[-1], [])\n",
    "    possible_words = filter_possible_words(possible_stresses, candidate_words)\n",
    "\n",
    "    return possible_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "ngram_dict = defaultdict(list)\n",
    "ngrams = zip(filtered_lower, filtered_lower[1:])\n",
    "for w1, w2 in ngrams:\n",
    "    ngram_dict[w1].append(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IH0 N', 'IH1 N']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.phones_for_word(\"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_possible_words(['shall', 'i', \"apologize\"], \"01\", ngram_dict)[-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(ngram_dict['emma']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
